{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f64548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports for creating a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e678fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySparkSession=SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"WordCount\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9966962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello hi how are you My name is Barış Hi Hi Hi How are you Hello there hello hello there',\n",
       " 'Hello apple where are where quark name is Barış Hi Hi Hi How are you Hello there hello hello there',\n",
       " 'My hi how are you My jupyter is hub Hi intelligence intelligent How are artificial Hello there hello intelligence there intelligence']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySparkContext=mySparkSession.sparkContext #creating spark context from spark session\n",
    "file_with_random_data = \"randomText.txt\"\n",
    "my_dataset = mySparkContext.textFile(file_with_random_data) #reading the txt file\n",
    "my_dataset.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7324af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[135] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "my_dataset=my_dataset.flatMap(lambda row: row.split(\" \"))  #splitting the txt file with blank.\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dc4e2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'hi',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Barış',\n",
       " 'Hi',\n",
       " 'Hi',\n",
       " 'Hi',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " 'Hello',\n",
       " 'there',\n",
       " 'hello',\n",
       " 'hello',\n",
       " 'there',\n",
       " 'Hello',\n",
       " 'apple',\n",
       " 'where',\n",
       " 'are',\n",
       " 'where']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.take(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68ecc158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[137] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "my_dataset = my_dataset.filter(lambda myWord: myWord!='') #removing the words which are empty space.\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "991fea9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'hi',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Barış',\n",
       " 'Hi',\n",
       " 'Hi',\n",
       " 'Hi',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " 'Hello',\n",
       " 'there',\n",
       " 'hello',\n",
       " 'hello',\n",
       " 'there',\n",
       " 'Hello',\n",
       " 'apple',\n",
       " 'where',\n",
       " 'are',\n",
       " 'where']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.take(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4977ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "print(type(my_dataset.take(25)))\n",
    "print(type(my_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9978a0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 1),\n",
       " ('hi', 1),\n",
       " ('how', 1),\n",
       " ('are', 1),\n",
       " ('you', 1),\n",
       " ('My', 1),\n",
       " ('name', 1),\n",
       " ('is', 1),\n",
       " ('Barış', 1),\n",
       " ('Hi', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset=my_dataset.map(lambda w:(w,1)) #mapping (assigning the count of 1 to. each word)\n",
    "my_dataset.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5398977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_dataset=my_dataset.map(lambda w:(w,1)) #mapping \n",
    "#my_dataset.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "517c5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = my_dataset.reduceByKey(lambda v1,v2:(v1+v2)) \n",
    "#reducing the counts of words by summing the word counts one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35e62daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique word number: 21\n",
      "PythonRDD[148] at RDD at PythonRDD.scala:53\n",
      "Hello\n",
      "\n",
      "\n",
      "\n",
      "******************* Some Statistics***********************\n",
      " Hello appears => 5 times in the randomText.txt file\n",
      " are appears => 6 times in the randomText.txt file\n",
      " name appears => 2 times in the randomText.txt file\n",
      " is appears => 3 times in the randomText.txt file\n",
      " Barış appears => 2 times in the randomText.txt file\n",
      " Hi appears => 7 times in the randomText.txt file\n",
      " there appears => 6 times in the randomText.txt file\n",
      " where appears => 2 times in the randomText.txt file\n",
      " jupyter appears => 1 times in the randomText.txt file\n",
      " artificial appears => 1 times in the randomText.txt file\n",
      " hi appears => 2 times in the randomText.txt file\n",
      " how appears => 2 times in the randomText.txt file\n",
      " you appears => 4 times in the randomText.txt file\n",
      " My appears => 3 times in the randomText.txt file\n",
      " How appears => 3 times in the randomText.txt file\n",
      " hello appears => 5 times in the randomText.txt file\n",
      " apple appears => 1 times in the randomText.txt file\n",
      " quark appears => 1 times in the randomText.txt file\n",
      " hub appears => 1 times in the randomText.txt file\n",
      " intelligence appears => 3 times in the randomText.txt file\n",
      " intelligent appears => 1 times in the randomText.txt file\n",
      "\n",
      "The word intelligent has the minimum occurence of 1\n",
      "The word Hi has the maximum occurence of 7\n",
      "******************* Some Statistics ***********************\n",
      "\n",
      "\n",
      "\n",
      "[('Hello', 5), ('are', 6), ('name', 2), ('is', 3), ('Barış', 2), ('Hi', 7), ('there', 6), ('where', 2), ('jupyter', 1), ('artificial', 1)]\n",
      "Hello\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "word_counts.take(40)\n",
    "unique_word_num = word_counts.count()\n",
    "print(\"Total unique word number: \" + str(unique_word_num))\n",
    "print(word_counts)\n",
    "print(word_counts.take(unique_word_num)[0][0])\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "max_occurence_num = -1 * (9 * int(pow(10,5)))\n",
    "max_occuring_word = \"Germany\"\n",
    "\n",
    "min_occurence_num = 9 * int(pow(10,5))\n",
    "min_occuring_word = \"Denmark\"\n",
    "\n",
    "\n",
    "print(\"******************* Some Statistics***********************\")\n",
    "for j in range(0,unique_word_num):\n",
    "    word = word_counts.take(unique_word_num)[j][0] \n",
    "    word_count = word_counts.take(unique_word_num)[j][1] \n",
    "    if(word_count >= max_occurence_num): #finding max occurence num for a word and the word which has the maximum number of occurence.\n",
    "        max_occurence_num = word_count\n",
    "        max_occuring_word = word\n",
    "    elif(word_count <= min_occurence_num):  #finding min occurence num for a word and the word which has the minimum number of occurence.\n",
    "        min_occurence_num = word_count\n",
    "        min_occuring_word = word\n",
    "    word = str(word) #convert to string\n",
    "    word_count = str(word_count) #convert to string\n",
    "    print(\" \"+word+\" appears => \"+word_count+\" times in the randomText.txt file\")\n",
    "\n",
    "\n",
    "print()    \n",
    "min_occurence_num = str(min_occurence_num)\n",
    "print(\"The word \"+min_occuring_word+\" has the minimum occurence of \"+min_occurence_num+\"\")\n",
    "max_occurence_num = str(max_occurence_num)\n",
    "print(\"The word \"+max_occuring_word+\" has the maximum occurence of \"+max_occurence_num+\"\")\n",
    "print(\"******************* Some Statistics ***********************\")\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(word_counts.take(10))\n",
    "print(word_counts.take(1)[0][0])  \n",
    "print(word_counts.take(1)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7366a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_sorted =my_dataset.reduceByKey(lambda c1,c2:(c1+c2)).sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcfdd42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Barış', 2),\n",
       " ('Hello', 5),\n",
       " ('Hi', 7),\n",
       " ('How', 3),\n",
       " ('My', 3),\n",
       " ('apple', 1),\n",
       " ('are', 6),\n",
       " ('artificial', 1),\n",
       " ('hello', 5),\n",
       " ('hi', 2),\n",
       " ('how', 2),\n",
       " ('hub', 1),\n",
       " ('intelligence', 3),\n",
       " ('intelligent', 1),\n",
       " ('is', 3),\n",
       " ('jupyter', 1),\n",
       " ('name', 2),\n",
       " ('quark', 1),\n",
       " ('there', 6),\n",
       " ('where', 2),\n",
       " ('you', 4)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_sorted.take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0e0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4346e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23933988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
